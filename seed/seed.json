[
  {
    "id": "kb-maintenance-comprehensive-guide",
    "category": "reference",
    "title": "Knowledge Base Maintenance and Defragmentation Guide",
    "tags": ["knowledge-base", "maintenance", "defragmentation", "workflow", "meta", "documentation", "layer:base"],
    "content": "# Knowledge Base Maintenance and Defragmentation Guide\n\n## Automatic Knowledge Capture\n\n### When to Save Knowledge Mid-Conversation\n\nUse `mcp__duckdb-kb__upsert_knowledge` when you encounter:\n\n#### 1. Novel Patterns (category: \"pattern\")\n- Discovered solutions to non-obvious problems\n- Performance optimization techniques that worked\n- Reusable architectural approaches\n- Best practices worth repeating\n\n**Example triggers:**\n- \"We just discovered X doesn't support Y, here's the workaround\"\n- \"This approach gave us 10x speedup\"\n- \"Non-deterministic behavior needs specific handling\"\n\n#### 2. Critical Fixes (category: \"troubleshooting\")\n- Bugs fixed and their root cause\n- \"This will bite us again\" moments\n- Gotchas and workarounds that took >30min to solve\n- Environment-specific quirks\n\n**Example triggers:**\n- \"System X has unexpected behavior with Y\"\n- \"Configuration Z speeds things up significantly\"\n- \"Edge case handling discovered\"\n\n#### 3. Important Decisions (category: \"issue\")\n- Architectural choices and their rationale\n- Trade-offs considered\n- Why we chose approach A over approach B\n- Milestone completions\n\n#### 4. Reusable Commands (category: \"command\")\n- New CLI commands or significant enhancements\n- Shell snippets worth repeating\n- Diagnostic procedures that proved useful\n\n**Do NOT save:**\n- ❌ One-off file reads or simple queries\n- ❌ Routine debugging (unless solution was non-obvious)\n- ❌ Trivial fixes\n- ❌ Information already well-documented\n\n### Self-Evaluation Before Saving\n\nAsk yourself:\n1. **Would future-me thank me for this?** (1 month from now)\n2. **Is this reusable?** (applies to >1 situation)\n3. **Did this take effort to figure out?** (>30min or non-obvious)\n4. **Is it better than existing docs?** (adds value)\n\nIf 3+ yes → save it immediately!\n\n## Knowledge Base Defragmentation\n\n### Understanding Fragmentation\n\nLike defragging a hard drive, knowledge fragmentation occurs when:\n- **Scattered information**: Same topic across 5 different entries\n- **Redundant content**: Duplicate information in multiple places\n- **Poor organization**: Related knowledge not grouped together\n- **Accumulated cruft**: Old session notes that should be consolidated patterns\n\n### When to Defragment\n\nTrigger consolidation when you notice:\n- **Fragmentation**: Same topic in 3+ separate entries\n- **Redundancy**: Copy-pasted content across entries\n- **Search pollution**: Too many results for common queries\n- **Staleness**: Old session notes that should be patterns\n- **Orphaned content**: One-off entries that could be merged\n\n### Defrag Process\n\n#### Step 1: Identify Clusters\nSearch for related topics:\n```python\nmcp__duckdb-kb__smart_search(\n    query=\"topic keyword\",\n    limit=20\n)\n# Review results - are 5+ entries about same thing?\n```\n\n#### Step 2: Consolidate\nMerge into comprehensive entry:\n- Create new consolidated entry with best content from all\n- Add cross-references/links between related entries\n- Delete or mark old entries as obsolete\n- Update with `upsert_knowledge` (overwrites old ID) or create new and delete old\n\n#### Step 3: Reorganize Tags\nStandardize taxonomy:\n- Merge variants: `performance` + `perf` + `speed` → `performance`\n- Add layer tags: `layer:base`, `layer:team`, `layer:personal`\n- Remove redundant tags\n\n#### Step 4: Update References\nFix broken links:\n- Search for entries referencing old IDs\n- Update to point to consolidated version\n\n### Maintenance Schedule\n\n**Daily/Per Session:**\n- Save notable insights immediately\n- Check for duplicates before creating new entries\n\n**Weekly:**\n- Review recent entries for quality\n- Consolidate if 3+ entries on same topic\n\n**Monthly:**\n- Run stats and identify bloated categories\n- Standardize tags\n- Merge session notes into permanent patterns\n\n**Quarterly:**\n- Full defragmentation pass\n- Update layer tags for distribution\n- Archive or delete obsolete entries\n- Review and improve organization\n\n## Quality Guidelines\n\n**Good Entry Characteristics:**\n- Descriptive ID (e.g., `pattern-error-handling-strategy`)\n- Clear title describing problem/solution\n- Well-structured markdown (Problem → Solution → Context → Example)\n- Appropriate category\n- Relevant, consistent tags\n- Layer tag if applicable\n\n**Signs of Fragmentation:**\n- Multiple entries with similar titles\n- Same tags on many unrelated entries\n- \"misc\" or \"other\" category overused\n- Session entries never consolidated\n- Search returns too many irrelevant results\n",
    "metadata": {}
  },
  {
    "id": "directive-auto-knowledge-capture",
    "category": "reference",
    "title": "Claude Directive: When to Save Knowledge Automatically",
    "tags": ["directive", "automation", "meta", "workflow", "layer:base"],
    "content": "# Claude Directive: Automatic Knowledge Capture\n\n## Purpose\nThis directive guides Claude on when to automatically save knowledge during conversations.\n\n## When to Save Knowledge (Automatic Detection)\n\nDuring conversations, save knowledge immediately when you encounter:\n\n### ✅ SAVE: Novel Patterns\n- Antipatterns discovered in any domain\n- Performance optimization techniques that worked\n- Reusable architectural approaches\n- Best practices and patterns\n\n### ✅ SAVE: Critical Fixes\n- Bugs and their root causes\n- Workarounds that took >30min to discover\n- Environment-specific quirks\n- \"This will bite us again\" moments\n\n### ✅ SAVE: Important Decisions\n- Architectural choices and rationale\n- Trade-offs considered\n- Milestone completions\n- Design decisions\n\n### ❌ DON'T SAVE: Routine Work\n- Simple file reads\n- Trivial fixes\n- Well-documented information\n- One-off debugging\n\n## Self-Evaluation Checklist\n\nBefore saving, ask yourself:\n1. **Would future-me thank me for this?** (1 month later)\n2. **Is this reusable?** (applies to >1 situation)\n3. **Did this take effort to figure out?** (>30min or non-obvious)\n4. **Is it better than existing docs?** (adds value)\n\nIf 3+ yes → save it immediately with `mcp__duckdb-kb__upsert_knowledge`!\n\n## How to Save\n\n```python\nmcp__duckdb-kb__upsert_knowledge({\n    \"id\": \"descriptive-kebab-case-id\",\n    \"category\": \"pattern|command|troubleshooting|reference|issue|other\",\n    \"title\": \"Clear Human Readable Title\",\n    \"tags\": [\"relevant\", \"tags\", \"layer:base\"],\n    \"content\": \"# Title\\n\\nWell-structured markdown content...\",\n    \"metadata\": {},\n    \"generate_embedding\": true\n})\n```\n\n## Quality Standards\n\n- Use descriptive IDs (not generic like \"entry-1\")\n- Write clear titles that describe the problem/solution\n- Structure content: Problem → Solution → Context → Example\n- Choose appropriate category\n- Add relevant tags (3-7 tags is ideal)\n- Generate embeddings for semantic search\n",
    "metadata": {}
  },
  {
    "id": "directive-conflict-detection",
    "category": "reference",
    "title": "Claude Directive: Conflict Detection and Resolution",
    "tags": ["directive", "defragmentation", "conflicts", "meta", "layer:base"],
    "content": "# Claude Directive: Conflict Detection and Resolution\n\n## Purpose\nWhen defragmenting or consolidating entries, ALWAYS check for conflicts and ask user for clarification when contradictory information is detected.\n\n## What Constitutes a Conflict\n\n**Conflicting information** = Same topic, different recommendations or contradictory facts\n\nExamples:\n- Entry A: \"Use approach X for performance\"\n- Entry B: \"Avoid approach X, use Y instead\"\n\n- Entry A: \"Run task weekly\"\n- Entry B: \"Run task daily\"\n\n- Entry A: \"Cost is $X\"\n- Entry B: \"Cost is $Y\" (where Y ≠ X)\n\n## When Conflicts Occur\n\n1. **During consolidation** - Merging multiple entries\n2. **During upsert** - New entry contradicts existing\n3. **During defrag** - Similar entries have different advice\n\n## Conflict Resolution Workflow\n\n### STEP 1: Identify the Conflict\n\nBefore saving any entry, search for similar content:\n\n```python\n# Search for similar entries\nresults = mcp__duckdb-kb__smart_search(\n    query=\"topic keywords\",\n    limit=10,\n    similarity_threshold=0.7\n)\n\n# Review results for contradictions\n# If similarity > 0.7 AND content contradicts, it's a conflict!\n```\n\n### STEP 2: Ask User for Clarification\n\nUse `AskUserQuestion` tool when conflict detected:\n\n```python\nAskUserQuestion(\n    questions=[{\n        \"question\": \"I found conflicting information about [TOPIC]. Which is correct?\",\n        \"header\": \"Conflict\",\n        \"multiSelect\": False,\n        \"options\": [\n            {\n                \"label\": \"Approach A\",\n                \"description\": \"Brief explanation from entry X\"\n            },\n            {\n                \"label\": \"Approach B\",\n                \"description\": \"Brief explanation from entry Y\"\n            },\n            {\n                \"label\": \"Both valid\",\n                \"description\": \"Both are correct in different contexts\"\n            },\n            {\n                \"label\": \"Neither\",\n                \"description\": \"I'll provide the correct approach\"\n            }\n        ]\n    }]\n)\n```\n\n### STEP 3: Consolidate Based on User Input\n\n- **One approach selected**: Keep that, mark other as obsolete or delete\n- **\"Both valid\"**: Consolidate into one entry explaining when to use each\n- **\"Neither\"**: Wait for user to provide correct information, then update\n\n### STEP 4: Update and Link\n\n- Update or create consolidated entry\n- Add links between related entries if keeping separate\n- Add metadata about resolution date\n- Tag with relevant version/date info if time-sensitive\n\n## Example: Detecting Conflict\n\n```python\n# You're about to save:\nnew_entry = {\n    \"id\": \"pattern-caching-strategy\",\n    \"content\": \"Always use cache strategy A for best results\"\n}\n\n# First, check for similar entries:\nexisting = mcp__duckdb-kb__smart_search(\n    query=\"caching strategy patterns\",\n    limit=5,\n    similarity_threshold=0.7\n)\n\n# Found existing entry:\n# - id: pattern-cache-invalidation\n# - similarity: 0.82\n# - content: \"Cache strategy A causes problems, use strategy B\"\n\n# ⚠️ CONFLICT DETECTED!\n# → Ask user which is correct before saving\n```\n\n## Proactive Conflict Prevention\n\nBefore saving ANY entry:\n\n1. ✅ Search for similar entries with `smart_search`\n2. ✅ Check similarity score > 0.7\n3. ✅ Review existing content carefully\n4. ✅ If contradiction detected → ask user via `AskUserQuestion`\n5. ✅ Only save after clarification or confirmation\n\n**This prevents the knowledge base from containing contradictory advice!**\n\n## Conflict Detection Thresholds\n\n- **Similarity > 0.9**: Likely duplicate, consider merging\n- **Similarity 0.7-0.9**: Related topic, check for conflicts\n- **Similarity < 0.7**: Different topics, probably no conflict\n",
    "metadata": {}
  },
  {
    "id": "duckdb-mcp-architecture",
    "category": "reference",
    "title": "DuckDB Knowledge Base MCP Server Architecture",
    "tags": ["architecture", "mcp", "duckdb", "meta", "layer:base"],
    "content": "# DuckDB Knowledge Base MCP Server Architecture\n\n## Overview\n\nThis MCP server provides Claude Code with hybrid SQL + semantic search capabilities over a DuckDB knowledge base.\n\n## Features\n\n- ✅ **10 comprehensive tools** (CRUD + search + utilities)\n- ✅ **Hybrid search** - SQL filtering + semantic similarity ranking\n- ✅ **OpenAI embeddings** (1536 dims) with local fallback\n- ✅ **Token-efficient** - ~4-5k token overhead\n- ✅ **Git-friendly** - Single .duckdb file with export options\n- ✅ **Fast** - In-memory DuckDB with VSS extension\n- ✅ **Offline-capable** - Only needs network for embedding generation\n\n## Architecture Diagram\n\n```\n┌─────────────────┐\n│   Claude Code   │\n└────────┬────────┘\n         │ MCP Protocol (JSON-RPC)\n         │\n┌────────┴────────┐\n│  mcp_server.py  │\n│                 │\n│  10 Tools:      │\n│  - get          │\n│  - list         │\n│  - query        │\n│  - find_similar │\n│  - smart_search │\n│  - upsert       │\n│  - delete       │\n│  - add_link     │\n│  - get_stats    │\n│  - gen_embed    │\n└────────┬────────┘\n         │\n         ├──────────────┐\n         │              │\n┌────────┴────────┐  ┌──┴──────────┐\n│ knowledge.duckdb│  │  OpenAI API │\n│                 │  │  (embeddings)│\n│ - knowledge     │  └─────────────┘\n│ - knowledge_links│\n│ - indexes       │\n│ - VSS extension │\n└─────────────────┘\n```\n\n## Available Tools\n\n### Read/Query Tools\n\n1. **get_knowledge** - Get single entry by ID\n2. **list_knowledge** - Browse/filter entries by category, tags, date\n3. **query_knowledge** - Execute custom SQL queries\n4. **find_similar** - Semantic search (conceptual similarity)\n5. **smart_search** - Hybrid SQL filters + semantic ranking\n\n### Write Tools\n\n6. **upsert_knowledge** - Create or update entry\n7. **delete_knowledge** - Delete entry and its links\n8. **add_link** - Create relationships between entries\n\n### Utility Tools\n\n9. **get_stats** - Database statistics and health\n10. **generate_embeddings** - Batch generate/regenerate embeddings\n\n## Token Efficiency\n\n| Operation | Traditional File Reading | DuckDB MCP | Savings |\n|-----------|-------------------------|------------|--------|\n| MCP overhead | N/A | 4-5k tokens | N/A |\n| Find entries | Read 5 files (10k) | SQL query (500) | 95% |\n| Semantic search | Full scan required | find_similar (800) | 90%+ |\n\n## Performance\n\n| Dataset Size | SQL Query | Semantic Search |\n|--------------|-----------|----------------|\n| 60 entries | < 1ms | ~2-5ms |\n| 1,000 entries | ~2ms | ~10ms |\n| 10,000 entries | ~5ms | ~15ms (with HNSW) |\n\n## Embedding Generation\n\n| Provider | Cost | Quality | Speed |\n|----------|------|---------|-------|\n| OpenAI | $0.0001/entry | Excellent (1536 dims) | 1-2s/entry |\n| Local | Free | Good (384 dims) | ~50ms/entry |\n\n## Extension Points\n\nEasy to extend:\n\n1. **Add new tool** - Add to `@app.list_tools()` and `call_tool()`\n2. **Add new category** - Just start using it, no schema change needed\n3. **Extend schema** - Alter table, add columns/indexes as needed\n4. **Change embedding model** - Update EMBEDDING_MODEL and regenerate\n\n## Three-Layer Architecture\n\nThis system supports three layers for different audiences:\n\n- **Layer 1 (base)**: Generic platform, distributable\n- **Layer 2 (team)**: Organization-specific extensions\n- **Layer 3 (personal)**: Individual's private knowledge\n\nSee `pattern-layer-tagging` entry for details.\n",
    "metadata": {}
  },
  {
    "id": "pattern-embedding-best-practices",
    "category": "pattern",
    "title": "Embedding Generation Best Practices",
    "tags": ["embeddings", "semantic-search", "openai", "performance", "layer:base"],
    "content": "# Embedding Generation Best Practices\n\n## When to Generate Embeddings\n\n### Always Generate\n\n- ✅ New entries added to knowledge base\n- ✅ Existing entries significantly updated\n- ✅ After bulk import of content\n- ✅ When switching embedding providers\n- ✅ After schema changes affecting content\n\n### Skip Generation\n\n- ❌ Minor typo fixes\n- ❌ Metadata-only updates (tags, category)\n- ❌ Adding links between entries\n- ❌ When embeddings already exist and content unchanged\n\n## Cost Optimization\n\n### OpenAI Embeddings\n\n**Model**: `text-embedding-3-small` (recommended)\n- **Cost**: ~$0.00002 per 1K tokens (~750 words)\n- **Dimensions**: 1536\n- **Quality**: Excellent\n\n**Typical costs:**\n- 100 entries (~500 words each): ~$0.001\n- 1,000 entries: ~$0.01\n- 10,000 entries: ~$0.10\n\n**Cost control:**\n```python\n# Only regenerate if content changed\nmcp__duckdb-kb__upsert_knowledge({\n    \"id\": \"my-entry\",\n    \"generate_embedding\": False  # Skip if just updating metadata\n})\n\n# Batch process efficiently\nmcp__duckdb-kb__generate_embeddings({\n    \"batch_size\": 32,  # Process in batches\n    \"regenerate\": False  # Only generate missing\n})\n```\n\n## Quality Guidelines\n\n### What to Embed\n\n**Good embedding content:**\n- Full entry content (title + body)\n- Rich descriptive text\n- Technical details and examples\n- Problem descriptions and solutions\n\n**Poor embedding content:**\n- Just titles (too short)\n- Code-only entries (semantic meaning unclear)\n- Lists of links with no context\n- Extremely short entries (<50 words)\n\n### Improving Semantic Search Quality\n\n1. **Write descriptive content**: More context = better embeddings\n2. **Use clear language**: Avoid excessive jargon without explanation\n3. **Include examples**: Helps embedding capture meaning\n4. **Add context**: Explain the \"why\" not just the \"what\"\n\n## Regeneration Strategy\n\n### When to Regenerate All\n\n- Switching embedding providers (OpenAI ↔ local)\n- Upgrading embedding model (e.g., v2 → v3)\n- Major content restructuring\n- Corrupted embeddings detected\n\n### Incremental Updates (Recommended)\n\n```python\n# Generate only for entries without embeddings\nmcp__duckdb-kb__generate_embeddings({\n    \"regenerate\": False\n})\n```\n\n## Local vs OpenAI\n\n| Feature | OpenAI | Local |\n|---------|--------|-------|\n| Cost | ~$0.01/1k entries | Free |\n| Quality | Excellent | Good |\n| Dimensions | 1536 | 384 |\n| Speed | 1-2s/entry | ~50ms/entry |\n| Network | Required | Offline |\n| Best for | Production | Development/testing |\n\n## Performance Tips\n\n### For Large Datasets (>1000 entries)\n\n```sql\n-- Add HNSW index for fast similarity search\nCREATE INDEX idx_knowledge_embedding_hnsw\nON knowledge\nUSING HNSW (embedding)\nWITH (metric = 'cosine');\n\n-- Speeds up semantic search 10-50x\n```\n\n### Batch Processing\n\n```python\n# Process in smaller batches to avoid rate limits\nmcp__duckdb-kb__generate_embeddings({\n    \"batch_size\": 32,  # OpenAI: 32, Local: can be higher\n    \"ids\": [\"entry1\", \"entry2\", ...]  # Optional: specific entries only\n})\n```\n\n## Monitoring\n\nCheck embedding coverage:\n\n```python\nmcp__duckdb-kb__get_stats({\"detailed\": True})\n\n# Look for:\n# - Total Entries vs With Embeddings\n# - Should be 100% in production\n# - <100% indicates missing embeddings\n```\n\n## Troubleshooting\n\n### \"No embeddings generated\"\n\n1. Check OpenAI API key is set\n2. Verify network connectivity\n3. Check API rate limits/quotas\n4. Try local fallback if needed\n\n### \"Semantic search returns poor results\"\n\n1. Check embeddings exist (`get_stats`)\n2. Lower similarity threshold (try 0.6 instead of 0.8)\n3. Review entry content quality\n4. Consider regenerating with better model\n",
    "metadata": {}
  },
  {
    "id": "pattern-semantic-search-tips",
    "category": "pattern",
    "title": "Semantic Search Best Practices",
    "tags": ["semantic-search", "embeddings", "search", "tips", "layer:base"],
    "content": "# Semantic Search Best Practices\n\n## Understanding Semantic Search\n\nSemantic search finds entries by **meaning** not just keywords.\n\n**Example:**\n- Query: \"slow database queries\"\n- Matches: \"performance optimization\", \"query tuning\", \"speed improvements\"\n- Why: Similar meaning, different words\n\n## When to Use Each Tool\n\n### find_similar\n\nBest for:\n- ✅ Conceptual searches (\"entries about X concept\")\n- ✅ Finding related/similar content\n- ✅ \"More like this\" queries\n- ✅ Vague or exploratory searches\n\n```python\nmcp__duckdb-kb__find_similar({\n    \"query\": \"handling errors in async code\",\n    \"limit\": 10,\n    \"similarity_threshold\": 0.7\n})\n```\n\n### smart_search\n\nBest for:\n- ✅ Filtered semantic search (\"recent entries about X\")\n- ✅ Category-specific searches\n- ✅ Tag-based with relevance ranking\n- ✅ Time-bounded queries\n\n```python\nmcp__duckdb-kb__smart_search({\n    \"query\": \"performance optimization techniques\",\n    \"category\": \"pattern\",\n    \"tags\": [\"performance\"],\n    \"date_after\": \"2025-10-01\",\n    \"limit\": 10\n})\n```\n\n### list_knowledge\n\nBest for:\n- ✅ Browsing by category\n- ✅ Filtering by exact tags\n- ✅ Getting recent entries\n- ✅ No semantic ranking needed\n\n```python\nmcp__duckdb-kb__list_knowledge({\n    \"category\": \"command\",\n    \"tags\": [\"backup\"],\n    \"limit\": 20\n})\n```\n\n### query_knowledge\n\nBest for:\n- ✅ Complex SQL queries\n- ✅ Aggregations and analytics\n- ✅ Custom filtering logic\n- ✅ Joins with knowledge_links\n\n```python\nmcp__duckdb-kb__query_knowledge({\n    \"sql\": \"SELECT category, COUNT(*) FROM knowledge GROUP BY category\"\n})\n```\n\n## Similarity Thresholds\n\n| Threshold | Meaning | Use Case |\n|-----------|---------|----------|\n| 0.9 - 1.0 | Nearly identical | Find duplicates |\n| 0.8 - 0.9 | Very similar | Related documentation |\n| 0.7 - 0.8 | Somewhat similar | Relevant topics |\n| 0.6 - 0.7 | Loosely related | Exploratory search |\n| < 0.6 | Unrelated | Probably not useful |\n\n**Default recommendation**: Start with 0.7, adjust based on results.\n\n## Writing Good Semantic Queries\n\n### ✅ Good Queries\n\n- **Descriptive**: \"error handling patterns for async operations\"\n- **Natural language**: \"how to improve query performance\"\n- **Concept-focused**: \"strategies for caching data\"\n- **Context-rich**: \"debugging connection timeout issues\"\n\n### ❌ Poor Queries\n\n- **Too short**: \"cache\" (use tags/category filter instead)\n- **Just keywords**: \"performance speed fast\" (use proper sentence)\n- **Too specific**: \"line 42 in file X\" (use exact match instead)\n- **Code snippets**: \"SELECT * FROM table\" (semantic search works on concepts)\n\n## Advanced Techniques\n\n### Hierarchical Search\n\nNarrow down progressively:\n\n```python\n# Step 1: Broad semantic search\nresults = smart_search({\"query\": \"caching strategies\", \"limit\": 20})\n\n# Step 2: Review and refine\nif too_many_results:\n    # Add filters\n    results = smart_search({\n        \"query\": \"caching strategies\",\n        \"category\": \"pattern\",\n        \"tags\": [\"performance\"],\n        \"limit\": 10\n    })\n```\n\n### Finding Related Clusters\n\n```python\n# Find all entries related to a concept\nresults = find_similar({\n    \"query\": \"detailed description of the concept\",\n    \"similarity_threshold\": 0.65,  # Lower threshold for broader net\n    \"limit\": 30\n})\n\n# Review for fragmentation - should these be consolidated?\n```\n\n### Discovering Connections\n\n```python\n# Start with one entry\nentry = get_knowledge({\"id\": \"some-entry\"})\n\n# Find semantically similar\nsimilar = find_similar({\n    \"query\": entry[\"content\"],\n    \"limit\": 10,\n    \"similarity_threshold\": 0.7\n})\n\n# Consider adding links between related entries\n```\n\n## Troubleshooting\n\n### \"No results found\"\n\n1. Lower similarity threshold (try 0.6)\n2. Simplify query (fewer constraints)\n3. Check embeddings exist (`get_stats`)\n4. Try different phrasing\n\n### \"Too many irrelevant results\"\n\n1. Raise similarity threshold (try 0.8)\n2. Add category/tag filters\n3. Use more specific query\n4. Add date constraints\n\n### \"Wrong results at top\"\n\n1. Refine query to be more specific\n2. Check if embeddings are stale (regenerate if needed)\n3. Add SQL filters to eliminate noise\n4. Consider if entries need better content\n\n## Performance Considerations\n\n- Semantic search is fast (~5ms for 100 entries)\n- Scales well with HNSW indexes (for >1000 entries)\n- Filtering (category/tags) happens before semantic ranking\n- Lower similarity thresholds = more computation\n",
    "metadata": {}
  },
  {
    "id": "pattern-knowledge-organization",
    "category": "pattern",
    "title": "Knowledge Organization Best Practices",
    "tags": ["organization", "naming", "tagging", "structure", "meta", "layer:base"],
    "content": "# Knowledge Organization Best Practices\n\n## ID Naming Conventions\n\n### Format: `category-topic-specifics`\n\nUse kebab-case (lowercase with hyphens):\n\n**Good IDs:**\n- `pattern-error-handling-async`\n- `command-backup-database`\n- `troubleshooting-connection-timeout`\n- `reference-api-documentation`\n- `issue-performance-investigation-2025-01`\n\n**Poor IDs:**\n- `entry1` (not descriptive)\n- `MyPattern` (not kebab-case)\n- `pattern_error_handling` (use hyphens, not underscores)\n- `asdfghjkl` (meaningless)\n\n### ID Guidelines\n\n1. **Descriptive**: ID should hint at content\n2. **Unique**: No duplicates\n3. **Stable**: Don't change IDs (breaks links)\n4. **Readable**: Easy to type and remember\n5. **Hierarchical**: Use prefixes to group related entries\n\n## Category System\n\nChoose the most specific category:\n\n| Category | Use For | Examples |\n|----------|---------|----------|\n| **pattern** | Reusable approaches, best practices | Design patterns, antipatterns, techniques |\n| **command** | CLI commands, scripts, procedures | Shell commands, maintenance scripts |\n| **troubleshooting** | Problems and solutions | Bug fixes, debugging, workarounds |\n| **reference** | Documentation, guides, specs | API docs, architecture, directives |\n| **issue** | Tracked items, investigations | Tickets, projects, decisions |\n| **other** | Miscellaneous (use sparingly) | Anything that doesn't fit above |\n\n## Tagging Strategy\n\n### How Many Tags?\n\n- **Minimum**: 3 tags\n- **Sweet spot**: 4-6 tags\n- **Maximum**: 10 tags (beyond this, probably too broad)\n\n### Tag Categories\n\n#### 1. Domain/Technology Tags\nWhat technology/domain:\n- `python`, `javascript`, `duckdb`, `mcp`\n\n#### 2. Purpose Tags\nWhat it's for:\n- `performance`, `security`, `debugging`, `testing`\n\n#### 3. Type Tags\nWhat kind of entry:\n- `best-practice`, `antipattern`, `gotcha`, `optimization`\n\n#### 4. Layer Tags\nWhich layer (for multi-layer setups):\n- `layer:base`, `layer:team`, `layer:personal`\n\n#### 5. Meta Tags\nAbout the KB itself:\n- `meta`, `directive`, `workflow`, `maintenance`\n\n### Tag Naming\n\n- **Lowercase**: `performance` not `Performance`\n- **Hyphenated**: `best-practice` not `best_practice`\n- **Singular**: `pattern` not `patterns` (easier to search)\n- **Consistent**: Pick one term and stick with it\n\n### Tag Maintenance\n\nAvoid proliferation:\n- ❌ `perf`, `performance`, `speed`, `fast` → ✅ `performance`\n- ❌ `db`, `database`, `databases` → ✅ `database`\n\nPeriodically audit tags:\n```python\nmcp__duckdb-kb__query_knowledge({\n    \"sql\": \"\"\"\n        SELECT unnest(tags) as tag, COUNT(*) as count\n        FROM knowledge\n        GROUP BY tag\n        ORDER BY count DESC\n    \"\"\"\n})\n```\n\n## Content Structure\n\nUse consistent markdown structure:\n\n```markdown\n# Title (H1 - only one per entry)\n\n## Problem / Context (H2)\nWhat issue does this address?\n\n## Solution (H2)\nHow to solve it\n\n## Example (H2)\nConcrete example with code/commands\n\n## References (H2 - optional)\nLinks to related entries, external docs\n```\n\n### Writing Style\n\n- **Be concise**: Get to the point\n- **Use examples**: Show, don't just tell\n- **Add context**: Explain why, not just how\n- **Link related entries**: Build connections\n- **Update regularly**: Keep information current\n\n## Metadata Usage\n\nStore additional structured data:\n\n```json\n{\n  \"metadata\": {\n    \"author\": \"optional\",\n    \"source\": \"where this knowledge came from\",\n    \"version\": \"if versioned\",\n    \"deprecated\": \"true if obsolete\",\n    \"superseded_by\": \"id-of-newer-entry\",\n    \"difficulty\": \"beginner|intermediate|advanced\"\n  }\n}\n```\n\n## Linking Entries\n\nCreate relationships:\n\n```python\nmcp__duckdb-kb__add_link({\n    \"from_id\": \"pattern-caching\",\n    \"to_id\": \"troubleshooting-cache-invalidation\",\n    \"link_type\": \"references\"\n})\n```\n\n**Link types:**\n- `related`: General relationship\n- `references`: Points to related info\n- `parent`: Broader topic\n- `child`: More specific subtopic\n\n## Organizational Antipatterns\n\n### ❌ Too Many \"Other\" Category\nIf >20% of entries are \"other\", categories are too narrow.\n\n### ❌ Inconsistent Naming\n`my-pattern`, `AnotherPattern`, `yet_another_pattern` → Pick one style!\n\n### ❌ Tag Explosion\n50 unique tags for 50 entries = no organization benefit\n\n### ❌ No Consolidation\n10 entries about same topic = fragmentation\n\n### ❌ Orphaned Entries\nEntries with no tags, no links, no context = hard to find\n\n## Quality Checklist\n\nBefore saving an entry:\n\n- [ ] ID is descriptive and kebab-case\n- [ ] Title clearly describes content\n- [ ] Category is appropriate\n- [ ] 4-6 relevant tags\n- [ ] Content is well-structured markdown\n- [ ] Examples included where helpful\n- [ ] Links to related entries added\n- [ ] Metadata populated if relevant\n- [ ] No duplicate information\n- [ ] Will generate embedding\n",
    "metadata": {}
  },
  {
    "id": "pattern-layer-tagging",
    "category": "pattern",
    "title": "Three-Layer Architecture and Tagging",
    "tags": ["layers", "architecture", "tagging", "distribution", "meta", "layer:base"],
    "content": "# Three-Layer Architecture and Tagging\n\n## Overview\n\nThe knowledge base supports a three-layer architecture for different audiences:\n\n```\nLayer 1: Base (Public)     ← Generic, distributable platform knowledge\nLayer 2: Team (Organization) ← Layer 1 + team/org-specific knowledge  \nLayer 3: Personal          ← Layers 1+2 + individual's private notes\n```\n\n## Layer Definitions\n\n### Layer 1: Base (duckdb-kb)\n\n**Audience**: Open source community, anyone wanting a knowledge base MCP\n\n**Content**:\n- Generic knowledge base platform documentation\n- DuckDB and MCP patterns (platform-agnostic)\n- Embedding and semantic search best practices\n- Defragmentation and maintenance guides\n- ~10-15 seed entries demonstrating the system\n\n**Tag**: `layer:base`\n\n**Goal**: Distributable, forkable, community-useful foundation\n\n### Layer 2: Team/Organization (custom name)\n\n**Audience**: Team members, organization developers\n\n**Content**: Everything from Layer 1, plus:\n- Organization-specific patterns\n- Technology stack patterns (specific to team)\n- Shared troubleshooting guides\n- Team architecture decisions\n- ~20-30 additional entries\n\n**Tag**: `layer:team` or `layer:[orgname]`\n\n**Note**: Person-agnostic (no personal notes, no individual tickets)\n\n### Layer 3: Personal (custom name)\n\n**Audience**: Individual user only\n\n**Content**: Everything from Layers 1 + 2, plus:\n- Personal issue tracking\n- Individual learning log\n- Private project notes\n- Session notes and investigations\n- All auto-imported content\n\n**Tag**: `layer:personal` or `layer:[username]`\n\n## Layer Tagging\n\n### Tagging Strategy\n\nAdd layer tag to EVERY entry:\n\n```python\nmcp__duckdb-kb__upsert_knowledge({\n    \"id\": \"pattern-caching\",\n    \"category\": \"pattern\",\n    \"title\": \"Caching Strategies\",\n    \"tags\": [\"caching\", \"performance\", \"layer:base\"],  # ← Layer tag\n    \"content\": \"...\"\n})\n```\n\n### Choosing the Right Layer\n\n**Ask yourself:**\n1. Is this useful to anyone using this knowledge base platform? → `layer:base`\n2. Is this specific to my team/organization? → `layer:team`\n3. Is this personal/private? → `layer:personal`\n\n**Examples:**\n\n| Entry | Layer | Why |\n|-------|-------|-----|\n| \"How to defragment knowledge base\" | base | Generic platform feature |\n| \"Our team's coding standards\" | team | Organization-specific |\n| \"My notes on project X\" | personal | Individual's work |\n| \"DuckDB embedding patterns\" | base | Platform knowledge |\n| \"How we use Oracle\" | team | Team's tech stack |\n| \"My Jira ticket IDR-1234\" | personal | Individual issue |\n\n## Export Filtering\n\nGenerate clean layers:\n\n```python\n# Export Layer 1 only (base)\nexport_layer(layer=\"base\", output=\"duckdb-kb-base.json\")\n\n# Export Layers 1+2 (team)\nexport_layer(layer=[\"base\", \"team\"], output=\"duckdb-kb-team.json\")\n\n# Export all layers (personal)\nexport_layer(layer=[\"base\", \"team\", \"personal\"], output=\"duckdb-kb-full.json\")\n```\n\n### Export Script\n\n```python\ndef export_layer(layers: list, output: str):\n    \"\"\"\n    Export entries matching specified layers\n    \"\"\"\n    con = get_connection()\n    \n    # Build layer filter\n    layer_filter = \" OR \".join([\n        f\"list_contains(tags, 'layer:{layer}')\"\n        for layer in layers\n    ])\n    \n    # Query entries\n    results = con.execute(f\"\"\"\n        SELECT *\n        FROM knowledge\n        WHERE {layer_filter}\n        ORDER BY created\n    \"\"\").fetchall()\n    \n    # Export to JSON\n    with open(output, 'w') as f:\n        json.dump(results, f, indent=2)\n```\n\n## Migration Between Layers\n\nMoving entries between layers:\n\n```python\n# Promote from personal to team (useful to others)\nentry = get_knowledge({\"id\": \"some-pattern\"})\nentry[\"tags\"].remove(\"layer:personal\")\nentry[\"tags\"].append(\"layer:team\")\nupsert_knowledge(entry)\n\n# Demote from base to team (too specific)\nentry = get_knowledge({\"id\": \"some-entry\"})\nentry[\"tags\"].remove(\"layer:base\")\nentry[\"tags\"].append(\"layer:team\")\nupsert_knowledge(entry)\n```\n\n## Directory Structure\n\n```\n~/knowledge-bases/\n├── duckdb-kb/           # Layer 1 - Base\n│   ├── mcp_server.py\n│   ├── knowledge.duckdb\n│   └── seed/\n│       └── base_seed.json\n│\n├── myteam-kb/           # Layer 2 - Team\n│   ├── extends: ../duckdb-kb/\n│   ├── mcp_server.py → ../duckdb-kb/mcp_server.py\n│   ├── knowledge.duckdb\n│   └── seed/\n│       └── team_seed.json\n│\n└── myname-kb/           # Layer 3 - Personal\n    ├── extends: ../myteam-kb/\n    ├── mcp_server.py → ../duckdb-kb/mcp_server.py\n    ├── knowledge.duckdb\n    └── seed/\n        └── personal_seed.json\n```\n\n## Distribution Workflow\n\n### Publishing Layer 1 (Base)\n\n1. Filter to base layer only\n2. Scrub any org-specific references\n3. Export clean seed data\n4. Package as distributable project\n5. Open source on GitHub\n\n### Sharing Layer 2 (Team)\n\n1. Export base + team layers\n2. Share within organization\n3. Team members fork and add Layer 3\n\n### Maintaining Layer 3 (Personal)\n\n1. Keep personal knowledge private\n2. Periodically promote useful patterns to Layer 2\n3. Layer 2 promoted patterns may eventually become Layer 1\n\n## Best Practices\n\n1. **Always tag with layer** - Makes filtering easy\n2. **Start specific, promote up** - Begin at Layer 3, promote useful patterns\n3. **Review periodically** - Quarterly review of layer assignments\n4. **No PII in base/team** - Keep sensitive info in Layer 3\n5. **Document layer intent** - README in each layer directory\n",
    "metadata": {}
  },
  {
    "id": "command-backup-restore",
    "category": "command",
    "title": "Backup and Restore Procedures",
    "tags": ["backup", "restore", "disaster-recovery", "maintenance", "layer:base"],
    "content": "# Backup and Restore Procedures\n\n## Why Backup?\n\nYour knowledge base is stored in a single `knowledge.duckdb` file. Loss or corruption would be catastrophic.\n\n## Backup Strategies\n\n### Strategy 1: Binary Backup (Fast, Complete)\n\n**Pros:**\n- Includes embeddings (no regeneration needed)\n- Fast backup and restore\n- Exact copy of database\n\n**Cons:**\n- Binary files not git-friendly\n- Larger file size\n- Less portable\n\n**How to:**\n```bash\n# Simple copy\ncp knowledge.duckdb knowledge.duckdb.backup\n\n# Timestamped backup\ncp knowledge.duckdb backups/knowledge_$(date +%Y%m%d_%H%M%S).duckdb\n\n# Automated script\n./backup.sh\n```\n\n### Strategy 2: JSON Export (Git-Friendly)\n\n**Pros:**\n- Human-readable\n- Git-friendly diffs\n- Easy to edit manually\n- Portable across systems\n\n**Cons:**\n- Doesn't include embeddings (must regenerate)\n- Slower to restore\n- Larger text files\n\n**How to:**\n```bash\n# Export to JSON\npython export.py\n\n# Creates: exports/knowledge_latest.json\n```\n\n### Strategy 3: SQL Dump\n\n**Pros:**\n- Readable SQL statements\n- Can selectively restore\n- Version control friendly\n\n**Cons:**\n- Doesn't include embeddings\n- Larger than binary\n\n**How to:**\n```bash\nduckdb knowledge.duckdb <<EOF\nEXPORT DATABASE 'exports/sql_backup' (FORMAT PARQUET);\nEOF\n```\n\n## Recommended Backup Schedule\n\n| Frequency | Method | Purpose |\n|-----------|--------|----------|\n| **After every major change** | Binary | Quick recovery point |\n| **Daily** | JSON export + git commit | Change tracking |\n| **Weekly** | Binary to external location | Off-site backup |\n| **Before upgrades** | Both | Safety net |\n\n## Backup Script\n\nCreate `backup.sh`:\n\n```bash\n#!/bin/bash\n# Knowledge Base Backup Script\n\nDB_PATH=\"knowledge.duckdb\"\nBACKUP_DIR=\"backups\"\nEXPORT_DIR=\"exports\"\nTIMESTAMP=$(date +%Y%m%d_%H%M%S)\n\n# Create directories if needed\nmkdir -p \"$BACKUP_DIR\" \"$EXPORT_DIR\"\n\n# Binary backup\necho \"Creating binary backup...\"\ncp \"$DB_PATH\" \"$BACKUP_DIR/knowledge_${TIMESTAMP}.duckdb\"\n\n# JSON export\necho \"Exporting to JSON...\"\npython export.py\n\n# Keep only last 7 binary backups\necho \"Cleaning old backups...\"\nls -t \"$BACKUP_DIR\"/knowledge_*.duckdb | tail -n +8 | xargs rm -f\n\necho \"Backup complete!\"\necho \"  Binary: $BACKUP_DIR/knowledge_${TIMESTAMP}.duckdb\"\necho \"  JSON: $EXPORT_DIR/knowledge_latest.json\"\n```\n\n## Restore Procedures\n\n### From Binary Backup\n\n```bash\n# Stop any MCP servers using the database first!\n\n# Restore from backup\ncp backups/knowledge_20250130_120000.duckdb knowledge.duckdb\n\n# Or use restore script\npython restore.py --from-backup backups/knowledge_20250130_120000.duckdb\n\n# Restart MCP server\n```\n\n### From JSON Export\n\n```bash\n# Restore schema and data\npython restore.py --from-json exports/knowledge_latest.json\n\n# Regenerate embeddings (REQUIRED)\nmcp__duckdb-kb__generate_embeddings({\n    \"regenerate\": False,\n    \"batch_size\": 32\n})\n\n# Or via script:\npython generate_embeddings.py\n```\n\n### Partial Restore (Selective)\n\n```python\n# Import only specific entries from JSON\nimport json\n\nwith open('exports/knowledge_latest.json') as f:\n    entries = json.load(f)\n\n# Filter entries\nto_restore = [e for e in entries if e['category'] == 'pattern']\n\n# Restore each\nfor entry in to_restore:\n    mcp__duckdb-kb__upsert_knowledge(entry)\n```\n\n## Disaster Recovery\n\n### Complete Loss Scenario\n\n1. **Restore from most recent binary backup**\n   ```bash\n   cp backups/knowledge_latest.duckdb knowledge.duckdb\n   ```\n\n2. **If no binary, restore from JSON**\n   ```bash\n   python restore.py --from-json exports/knowledge_latest.json\n   python generate_embeddings.py\n   ```\n\n3. **Verify integrity**\n   ```python\n   mcp__duckdb-kb__get_stats({\"detailed\": True})\n   # Check entry count, embedding coverage\n   ```\n\n### Corruption Detection\n\nSigns of corruption:\n- DuckDB connection errors\n- Missing entries\n- Broken embeddings\n- Query failures\n\n**Recovery:**\n```bash\n# Try to repair\nduckdb knowledge.duckdb \"CHECKPOINT;\"\n\n# If fails, restore from backup\ncp backups/knowledge_latest.duckdb knowledge.duckdb\n```\n\n## Backup Validation\n\nPeriodically test backups:\n\n```bash\n# Test restore to temporary database\npython restore.py \\\n    --from-backup backups/knowledge_latest.duckdb \\\n    --output test_restore.duckdb\n\n# Verify\nduckdb test_restore.duckdb \"SELECT COUNT(*) FROM knowledge;\"\n\n# Clean up\nrm test_restore.duckdb\n```\n\n## Automation\n\n### Daily Backup Cron Job\n\n```bash\n# Add to crontab: crontab -e\n0 2 * * * cd /path/to/duckdb-kb && ./backup.sh\n```\n\n### Git Auto-Commit\n\n```bash\n#!/bin/bash\n# Auto-commit JSON exports\n\ncd /path/to/duckdb-kb\npython export.py\n\nif [[ -n $(git status -s exports/) ]]; then\n    git add exports/knowledge_latest.json\n    git commit -m \"Backup: $(date +%Y-%m-%d)\"\n    git push\nfi\n```\n\n## Best Practices\n\n1. ✅ **Multiple backup types** - Binary + JSON\n2. ✅ **Off-site backups** - Cloud storage, external drive\n3. ✅ **Test restores** - Verify backups work\n4. ✅ **Automate** - Scheduled backups via cron\n5. ✅ **Version control JSON exports** - Git history\n6. ✅ **Before major changes** - Always backup first\n7. ✅ **Document recovery** - Keep this guide accessible\n",
    "metadata": {}
  },
  {
    "id": "troubleshooting-missing-embeddings",
    "category": "troubleshooting",
    "title": "Missing Embeddings Troubleshooting",
    "tags": ["embeddings", "troubleshooting", "openai", "layer:base"],
    "content": "# Missing Embeddings Troubleshooting\n\n## Symptoms\n\n- Semantic search returns no results\n- `get_stats` shows entries without embeddings\n- \"No embeddings found\" errors\n- Similarity scores all 0\n\n## Diagnosis\n\nCheck embedding coverage:\n\n```python\nmcp__duckdb-kb__get_stats({\"detailed\": True})\n\n# Look for:\n# Total Entries: 100\n# With Embeddings: 85  ← Should be 100%\n```\n\nIdentify entries without embeddings:\n\n```python\nmcp__duckdb-kb__query_knowledge({\n    \"sql\": \"SELECT id, title FROM knowledge WHERE embedding IS NULL\"\n})\n```\n\n## Common Causes\n\n### 1. Embeddings Never Generated\n\n**Symptom**: New entries have no embeddings\n\n**Cause**: `generate_embedding: false` when creating entry\n\n**Fix**:\n```python\n# Generate for all missing entries\nmcp__duckdb-kb__generate_embeddings({\n    \"regenerate\": False  # Only generate missing\n})\n```\n\n### 2. OpenAI API Key Not Set\n\n**Symptom**: \"API key not found\" errors\n\n**Cause**: `OPENAI_API_KEY` environment variable not set\n\n**Fix**:\n```bash\n# Check if set\necho $OPENAI_API_KEY\n\n# Set in MCP config\n{\n  \"mcpServers\": {\n    \"duckdb-kb\": {\n      \"env\": {\n        \"OPENAI_API_KEY\": \"sk-...\"\n      }\n    }\n  }\n}\n\n# Or export in shell\nexport OPENAI_API_KEY=\"sk-...\"\n```\n\n### 3. OpenAI API Rate Limit\n\n**Symptom**: Some embeddings generated, then stops\n\n**Cause**: Hit rate limits (3,000 requests/min for free tier)\n\n**Fix**:\n```python\n# Generate in smaller batches with delays\nmcp__duckdb-kb__generate_embeddings({\n    \"batch_size\": 10,  # Smaller batches\n    \"regenerate\": False\n})\n\n# Wait and retry if needed\n```\n\n### 4. Network Connectivity Issues\n\n**Symptom**: Timeout errors during generation\n\n**Cause**: No internet or OpenAI API unreachable\n\n**Fix**:\n```bash\n# Test connectivity\ncurl https://api.openai.com/v1/models\n\n# Use local fallback\nexport EMBEDDING_PROVIDER=\"local\"\npip install sentence-transformers torch\n```\n\n### 5. Restored from JSON Without Regenerating\n\n**Symptom**: All entries missing embeddings after restore\n\n**Cause**: JSON exports don't include embeddings\n\n**Fix**:\n```python\n# After JSON restore, always regenerate\nmcp__duckdb-kb__generate_embeddings({\n    \"regenerate\": False\n})\n```\n\n### 6. OpenAI Account Issue\n\n**Symptom**: \"Insufficient quota\" or \"Invalid API key\"\n\n**Cause**: Account lacks credits or key expired\n\n**Fix**:\n- Check OpenAI account: https://platform.openai.com/usage\n- Add payment method if needed\n- Generate new API key if expired\n- Use local fallback temporarily\n\n## Manual Embedding Generation\n\n### For Specific Entries\n\n```python\nmcp__duckdb-kb__generate_embeddings({\n    \"ids\": [\"entry-1\", \"entry-2\", \"entry-3\"],\n    \"regenerate\": True\n})\n```\n\n### For All Missing\n\n```python\nmcp__duckdb-kb__generate_embeddings({\n    \"regenerate\": False,  # Skip existing\n    \"batch_size\": 32\n})\n```\n\n### Using Script\n\n```bash\nexport OPENAI_API_KEY=\"sk-...\"\npython generate_embeddings.py\n```\n\n## Verification\n\nAfter generating, verify:\n\n```python\n# Check stats\nstats = mcp__duckdb-kb__get_stats({\"detailed\": True})\nprint(f\"Coverage: {stats['With Embeddings']}/{stats['Total Entries']}\")\n\n# Test semantic search\nresults = mcp__duckdb-kb__find_similar({\n    \"query\": \"test query\",\n    \"limit\": 5\n})\nprint(f\"Found {len(results)} results\")\n```\n\n## Local Embedding Fallback\n\nIf OpenAI unavailable, use local model:\n\n```bash\n# Install dependencies\npip install sentence-transformers torch\n\n# Set environment variable\nexport EMBEDDING_PROVIDER=\"local\"\n\n# Generate embeddings\npython generate_embeddings.py\n```\n\n**Note**: Local embeddings are:\n- ✅ Free and offline\n- ✅ Fast (~50ms per entry)\n- ⚠️ Lower quality (384 dims vs 1536)\n- ⚠️ Require more storage (model files)\n\n## Prevention\n\n1. ✅ **Always generate embeddings** when creating entries\n2. ✅ **Monitor embedding coverage** via stats\n3. ✅ **Set API key in MCP config** not just shell\n4. ✅ **Backup includes embeddings** (binary backup)\n5. ✅ **Test embedding generation** after setup\n6. ✅ **Set up alerts** for low coverage (<95%)\n\n## Emergency Workaround\n\nIf embeddings can't be generated:\n\n```python\n# Use SQL-only queries instead of semantic search\nmcp__duckdb-kb__list_knowledge({\n    \"category\": \"pattern\",\n    \"tags\": [\"performance\"]\n})\n\n# Or SQL query\nmcp__duckdb-kb__query_knowledge({\n    \"sql\": \"SELECT * FROM knowledge WHERE content LIKE '%search term%'\"\n})\n```\n\n**Note**: This loses semantic search benefits but keeps system functional.\n",
    "metadata": {}
  },
  {
    "id": "troubleshooting-slow-semantic-search",
    "category": "troubleshooting",
    "title": "Slow Semantic Search Performance",
    "tags": ["performance", "semantic-search", "optimization", "troubleshooting", "layer:base"],
    "content": "# Slow Semantic Search Performance\n\n## Symptoms\n\n- Semantic search takes >5 seconds\n- `find_similar` or `smart_search` timeouts\n- High CPU usage during searches\n- System becomes unresponsive\n\n## Performance Benchmarks\n\n| Dataset Size | Expected Time | Slow If |\n|--------------|---------------|----------|\n| <100 entries | <10ms | >100ms |\n| 100-1K entries | 10-50ms | >500ms |\n| 1K-10K entries | 50-200ms | >2s |\n| >10K entries | 200ms-1s | >5s |\n\n## Common Causes\n\n### 1. No HNSW Index (Large Datasets)\n\n**Symptom**: Linear slowdown as dataset grows\n\n**Cause**: Brute-force similarity search without index\n\n**Fix**: Add HNSW index\n\n```sql\n-- Connect to database\nduckdb knowledge.duckdb\n\n-- Check if VSS extension loaded\nSELECT * FROM duckdb_extensions() WHERE extension_name = 'vss';\n\n-- Load if needed\nINSTALL vss;\nLOAD vss;\n\n-- Create HNSW index\nCREATE INDEX idx_knowledge_embedding_hnsw\nON knowledge\nUSING HNSW (embedding)\nWITH (metric = 'cosine');\n\n-- Verify index exists\n.indexes\n```\n\n**Improvement**: 10-50x faster for >1000 entries\n\n### 2. Too Many Results Requested\n\n**Symptom**: Slow when `limit` is high (>50)\n\n**Cause**: Computing similarity for many results\n\n**Fix**: Request fewer results\n\n```python\n# Instead of:\nfind_similar({\"query\": \"...\", \"limit\": 100})  # Slow\n\n# Use:\nfind_similar({\"query\": \"...\", \"limit\": 10})   # Fast\n```\n\n### 3. Low Similarity Threshold\n\n**Symptom**: Slow when threshold < 0.5\n\n**Cause**: Must check nearly all entries\n\n**Fix**: Raise threshold\n\n```python\n# Instead of:\nfind_similar({\"query\": \"...\", \"similarity_threshold\": 0.3})  # Slow\n\n# Use:\nfind_similar({\"query\": \"...\", \"similarity_threshold\": 0.7})   # Fast\n```\n\n### 4. Embedding Generation During Search\n\n**Symptom**: First search slow, subsequent searches fast\n\n**Cause**: Query embedding being generated on-demand\n\n**This is normal**: Query embedding must be generated each time\n\n**Optimization**: Use cached queries if repeating same search\n\n### 5. Large Embedding Dimensions\n\n**Symptom**: Consistently slow across all searches\n\n**Cause**: Using high-dimensional embeddings (e.g., 3072 dims)\n\n**Fix**: Use standard model\n\n```python\n# In mcp_server.py\nEMBEDDING_MODEL = 'text-embedding-3-small'  # 1536 dims (recommended)\n# Not: 'text-embedding-3-large'  # 3072 dims (slower)\n```\n\n### 6. Database Not In Memory\n\n**Symptom**: Slow on first search, faster after\n\n**Cause**: Database on disk, not cached in memory\n\n**Fix**: Ensure DuckDB uses memory efficiently\n\n```python\n# In mcp_server.py, ensure connection settings:\ncon = duckdb.connect(DB_PATH)\ncon.execute(\"SET memory_limit='2GB'\")  # Adjust based on your system\ncon.execute(\"SET threads=4\")  # Use multiple cores\n```\n\n## Optimization Strategies\n\n### For <1K Entries (Brute Force OK)\n\n```python\n# No index needed, but optimize queries:\n- Keep limit ≤ 20\n- Use similarity_threshold ≥ 0.6\n- Filter by category/tags first (smart_search)\n```\n\n### For 1K-10K Entries (HNSW Index)\n\n```sql\n-- Create HNSW index (do once)\nCREATE INDEX idx_knowledge_embedding_hnsw\nON knowledge\nUSING HNSW (embedding);\n```\n\n### For >10K Entries (Advanced)\n\n```sql\n-- HNSW with optimized parameters\nCREATE INDEX idx_knowledge_embedding_hnsw\nON knowledge\nUSING HNSW (embedding)\nWITH (\n    metric = 'cosine',\n    ef_construction = 128,  -- Higher = better quality, slower build\n    M = 16  -- Higher = better quality, more memory\n);\n\n-- Partition by category if diverse content\nCREATE INDEX idx_category ON knowledge(category);\n\n-- Use smart_search to filter first, then rank semantically\n```\n\n## Monitoring Performance\n\n### Measure Query Time\n\n```python\nimport time\n\nstart = time.time()\nresults = mcp__duckdb-kb__find_similar({\n    \"query\": \"test query\",\n    \"limit\": 10\n})\nelapsed = time.time() - start\n\nprint(f\"Search took {elapsed:.3f}s\")\nprint(f\"Found {len(results)} results\")\n```\n\n### Check Index Usage\n\n```sql\n-- See query plan\nEXPLAIN SELECT * FROM knowledge\nORDER BY array_cosine_similarity(embedding, [...])\nLIMIT 10;\n\n-- Should show \"HNSW INDEX SCAN\" if index used\n```\n\n## Quick Fixes\n\nTry these in order:\n\n1. ✅ Add HNSW index (biggest impact)\n2. ✅ Reduce `limit` to 10-20\n3. ✅ Raise `similarity_threshold` to 0.7\n4. ✅ Use `smart_search` with category filter\n5. ✅ Increase DuckDB memory limit\n6. ✅ Use fewer embedding dimensions\n\n## When to Worry\n\n**Normal**:\n- First query slower (embedding generation)\n- <100ms for <1K entries\n- <500ms for >1K entries with HNSW\n\n**Investigate**:\n- >1s for any query\n- Progressively slower over time\n- CPU pegged at 100%\n- Out of memory errors\n\n## Testing Performance\n\n```python\n# Benchmark script\nimport time\n\nqueries = [\n    \"performance optimization\",\n    \"error handling patterns\",\n    \"database configuration\",\n    \"backup procedures\",\n    \"troubleshooting guide\"\n]\n\ntimes = []\nfor query in queries:\n    start = time.time()\n    mcp__duckdb-kb__find_similar({\n        \"query\": query,\n        \"limit\": 10,\n        \"similarity_threshold\": 0.7\n    })\n    elapsed = time.time() - start\n    times.append(elapsed)\n    print(f\"{query}: {elapsed:.3f}s\")\n\navg_time = sum(times) / len(times)\nprint(f\"\\nAverage: {avg_time:.3f}s\")\nprint(f\"Max: {max(times):.3f}s\")\n```\n\nTarget: Average <100ms, Max <500ms\n",
    "metadata": {}
  },
  {
    "id": "reference-mcp-server-tools",
    "category": "reference",
    "title": "MCP Server Tools Reference",
    "tags": ["mcp", "tools", "api", "reference", "layer:base"],
    "content": "# MCP Server Tools Reference\n\n## Overview\n\nThe DuckDB Knowledge Base MCP server provides 10 tools for Claude Code to interact with the knowledge base.\n\n## Tool Categories\n\n### Read/Query Tools (5)\n1. `get_knowledge` - Get single entry by ID\n2. `list_knowledge` - Browse/filter entries\n3. `query_knowledge` - Execute custom SQL\n4. `find_similar` - Semantic search\n5. `smart_search` - Hybrid SQL + semantic\n\n### Write Tools (3)\n6. `upsert_knowledge` - Create/update entry\n7. `delete_knowledge` - Delete entry\n8. `add_link` - Create relationships\n\n### Utility Tools (2)\n9. `get_stats` - Database statistics\n10. `generate_embeddings` - Batch generate embeddings\n\n---\n\n## Read/Query Tools\n\n### 1. get_knowledge\n\nGet a single knowledge entry by ID.\n\n**Parameters:**\n```json\n{\n  \"id\": \"entry-id\",           // Required: Entry ID\n  \"include_related\": false    // Optional: Include linked entries\n}\n```\n\n**Returns:**\n```json\n{\n  \"id\": \"entry-id\",\n  \"category\": \"pattern\",\n  \"title\": \"Entry Title\",\n  \"tags\": [\"tag1\", \"tag2\"],\n  \"content\": \"Full markdown content...\",\n  \"metadata\": {},\n  \"created\": \"2025-01-01T00:00:00\",\n  \"updated\": \"2025-01-02T00:00:00\",\n  \"has_embedding\": true\n}\n```\n\n**Use Cases:**\n- Retrieve specific entry details\n- Check if entry exists\n- Get related entries via links\n\n---\n\n### 2. list_knowledge\n\nList and filter knowledge entries.\n\n**Parameters:**\n```json\n{\n  \"category\": \"pattern\",         // Optional: Filter by category\n  \"tags\": [\"performance\"],       // Optional: Filter by tags (OR logic)\n  \"date_after\": \"2025-01-01\",    // Optional: Only entries after date\n  \"limit\": 20,                   // Optional: Max results (default 20)\n  \"offset\": 0                    // Optional: Pagination offset\n}\n```\n\n**Returns:**\n```json\n{\n  \"count\": 15,\n  \"entries\": [\n    {\n      \"id\": \"...\",\n      \"category\": \"...\",\n      \"title\": \"...\",\n      \"tags\": [...],\n      \"content_preview\": \"First 200 chars...\",\n      \"created\": \"...\",\n      \"updated\": \"...\"\n    }\n  ]\n}\n```\n\n**Use Cases:**\n- Browse by category\n- Find recently updated entries\n- Filter by tags\n- Pagination through results\n\n---\n\n### 3. query_knowledge\n\nExecute custom SQL queries.\n\n**Parameters:**\n```json\n{\n  \"sql\": \"SELECT * FROM knowledge WHERE category = 'pattern'\"\n}\n```\n\n**Returns:**\nQuery results as JSON array.\n\n**Use Cases:**\n- Complex filtering\n- Aggregations and analytics\n- Custom reporting\n- Joins with knowledge_links table\n\n**Example Queries:**\n\n```sql\n-- Count by category\nSELECT category, COUNT(*) as count\nFROM knowledge\nGROUP BY category;\n\n-- Tag frequency\nSELECT unnest(tags) as tag, COUNT(*) as usage\nFROM knowledge\nGROUP BY tag\nORDER BY usage DESC\nLIMIT 20;\n\n-- Entries without embeddings\nSELECT id, title\nFROM knowledge\nWHERE embedding IS NULL;\n\n-- Recently updated\nSELECT id, title, updated\nFROM knowledge\nORDER BY updated DESC\nLIMIT 10;\n```\n\n---\n\n### 4. find_similar\n\nSemantic search by meaning/concept.\n\n**Parameters:**\n```json\n{\n  \"query\": \"search query text\",       // Required: Natural language query\n  \"category\": \"pattern\",              // Optional: Filter by category\n  \"similarity_threshold\": 0.7,        // Optional: Min similarity (0-1, default 0.6)\n  \"limit\": 10                         // Optional: Max results (default 10)\n}\n```\n\n**Returns:**\n```json\n[\n  {\n    \"id\": \"entry-id\",\n    \"title\": \"Entry Title\",\n    \"category\": \"pattern\",\n    \"tags\": [...],\n    \"content_preview\": \"...\",\n    \"similarity_score\": 0.85,\n    \"created\": \"...\",\n    \"updated\": \"...\"\n  }\n]\n```\n\n**Use Cases:**\n- Find conceptually similar entries\n- \"More like this\" queries\n- Exploratory search\n- Find related documentation\n\n---\n\n### 5. smart_search\n\nHybrid SQL filters + semantic ranking.\n\n**Parameters:**\n```json\n{\n  \"query\": \"search query text\",       // Required: Natural language query\n  \"category\": \"pattern\",              // Optional: Filter by category\n  \"tags\": [\"performance\"],            // Optional: Filter by tags\n  \"date_after\": \"2025-01-01\",        // Optional: Filter by date\n  \"similarity_threshold\": 0.6,        // Optional: Min similarity\n  \"limit\": 10                         // Optional: Max results\n}\n```\n\n**Returns:**\nSame format as `find_similar`.\n\n**Use Cases:**\n- \"Recent entries about X\"\n- Category-specific semantic search\n- Tag-based with relevance ranking\n- Time-bounded queries\n\n---\n\n## Write Tools\n\n### 6. upsert_knowledge\n\nCreate or update a knowledge entry.\n\n**Parameters:**\n```json\n{\n  \"id\": \"unique-entry-id\",           // Required: Entry ID (kebab-case)\n  \"category\": \"pattern\",              // Required: Category\n  \"title\": \"Entry Title\",            // Required: Human-readable title\n  \"content\": \"# Markdown content\",   // Required: Full content\n  \"tags\": [\"tag1\", \"tag2\"],          // Required: Array of tags\n  \"metadata\": {},                     // Optional: JSON metadata\n  \"generate_embedding\": true         // Optional: Generate embedding (default true)\n}\n```\n\n**Returns:**\nSuccess message with entry ID.\n\n**Behavior:**\n- If ID exists: Updates entry, regenerates embedding if requested\n- If ID new: Creates entry, generates embedding\n\n**Use Cases:**\n- Add new knowledge\n- Update existing entries\n- Batch import content\n\n---\n\n### 7. delete_knowledge\n\nDelete a knowledge entry.\n\n**Parameters:**\n```json\n{\n  \"id\": \"entry-id\"  // Required: Entry ID to delete\n}\n```\n\n**Returns:**\nSuccess message.\n\n**Behavior:**\n- Deletes entry from database\n- Removes all links to/from this entry\n- Cannot be undone (backup first!)\n\n**Use Cases:**\n- Remove obsolete entries\n- Clean up duplicates after consolidation\n- Delete outdated information\n\n---\n\n### 8. add_link\n\nCreate relationship between entries.\n\n**Parameters:**\n```json\n{\n  \"from_id\": \"entry-1\",         // Required: Source entry ID\n  \"to_id\": \"entry-2\",           // Required: Target entry ID\n  \"link_type\": \"related\"        // Optional: Link type (default \"related\")\n}\n```\n\n**Link Types:**\n- `related` - General relationship\n- `references` - Points to related info\n- `parent` - Broader topic\n- `child` - More specific subtopic\n\n**Returns:**\nSuccess message.\n\n**Use Cases:**\n- Connect related entries\n- Build knowledge graph\n- Track references\n- Organize hierarchies\n\n---\n\n## Utility Tools\n\n### 9. get_stats\n\nGet database statistics.\n\n**Parameters:**\n```json\n{\n  \"detailed\": true  // Optional: Include detailed breakdown (default false)\n}\n```\n\n**Returns:**\n```json\n{\n  \"summary\": {\n    \"Total Entries\": \"100\",\n    \"With Embeddings\": \"100\",\n    \"Categories\": \"5\",\n    \"Unique Tags\": \"42\",\n    \"Total Links\": \"25\"\n  },\n  \"by_category\": [\n    {\n      \"category\": \"pattern\",\n      \"count\": 30,\n      \"embeddings_generated\": 30,\n      \"embedding_pct\": 100\n    }\n  ],\n  \"top_tags\": [\n    {\n      \"tag\": \"performance\",\n      \"count\": 20,\n      \"categories\": [\"pattern\", \"troubleshooting\"]\n    }\n  ]\n}\n```\n\n**Use Cases:**\n- Health check\n- Monitor embedding coverage\n- Analyze content distribution\n- Identify bloated categories\n\n---\n\n### 10. generate_embeddings\n\nBatch generate or regenerate embeddings.\n\n**Parameters:**\n```json\n{\n  \"ids\": [\"entry-1\", \"entry-2\"],  // Optional: Specific entries (all if not specified)\n  \"regenerate\": false,             // Optional: Regenerate existing (default false)\n  \"batch_size\": 32                 // Optional: Batch size (default 32)\n}\n```\n\n**Returns:**\n```json\n{\n  \"status\": \"success\",\n  \"total_entries\": 100,\n  \"updated\": 100,\n  \"provider\": \"OpenAI\",\n  \"model\": \"text-embedding-3-small\",\n  \"dimensions\": 1536\n}\n```\n\n**Use Cases:**\n- Generate embeddings after bulk import\n- Fix missing embeddings\n- Regenerate after model change\n- Initial setup\n\n---\n\n## Tool Selection Guide\n\n| Task | Tool |\n|------|------|\n| Get specific entry | `get_knowledge` |\n| Browse by category | `list_knowledge` |\n| Search by concept | `find_similar` |\n| Recent entries about X | `smart_search` |\n| Complex query | `query_knowledge` |\n| Add/update entry | `upsert_knowledge` |\n| Remove entry | `delete_knowledge` |\n| Link entries | `add_link` |\n| Check health | `get_stats` |\n| Fix embeddings | `generate_embedings` |\n",
    "metadata": {}
  }
]
